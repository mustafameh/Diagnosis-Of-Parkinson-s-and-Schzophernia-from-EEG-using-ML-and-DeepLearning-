{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a15e7b8-eb9e-4df4-ac7d-a553365095b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from features import concatenate_features\n",
    "from read_data import read_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1ff3b19-e8fd-411d-a6f5-23a8129b732c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "all_fp=glob('all_SP_edf/*.edf') #the path of all files is in all_fp\n",
    "\n",
    "healthy_fp= [ i for i in all_fp if 'h' in i.split('\\\\')[1]] #List of path of all healthy subjects\n",
    "patient_fp= [ i for i in all_fp if 's' in i.split('\\\\')[1]]#List path of all sick subjects\n",
    "\n",
    "healthy_epochs_array=[read_data(i) for i in healthy_fp] # (no of healthy subjects) * (No.of epochs/trials, channels, length of signal)\n",
    "patient_epochs_array=[read_data(i) for i in patient_fp] # # (no of Sick subjects) * (No.of epochs/trials, channels, length of signal)\n",
    "\n",
    "data_list=healthy_epochs_array+patient_epochs_array\n",
    "\n",
    "data_array = np.vstack(data_list)#converting to numpy array, (#total trails , #no of channels, #length of signal) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0311795-5879-439a-9793-f18a28cb4251",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9605, 247)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=[] #stores the extracted features list, features are extracted channel wise and concatenated together\n",
    "\n",
    "for data in data_array:\n",
    "    features.append(concatenate_features(data)) #calculates all features for each trial\n",
    "    \n",
    "features_array = np.array(features)\n",
    "features_array.shape # (no of epochs/trials, #number of channels*number of features) #pehley channel key 13 uskey bad doesrey channel key 13 and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdd4c505-1361-46f7-bac0-b963a94f6d02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 9605 (9605,)\n"
     ]
    }
   ],
   "source": [
    "##Label\n",
    "#We have features array till now time for target/label array, whats tricky about splitting the data\n",
    "\n",
    "#i guess label array shouldnt be split for training and testing since the model would have already seen the data from the same patient  as it\n",
    "# would be splitting based on epochs and epochs can be from the same patient\n",
    "\n",
    "#creating lables 0 for healthy and 1 for pd\n",
    "healthy_epochs_array_lable= [[0]*len(i) for i in healthy_epochs_array ]# create arrays with 0's, where number of zeros in each entry is equal to the number of trials in that file, for eg first entry will have 47 0's\n",
    "patient_epochs_array_lable= [[1]*len(i) for i in patient_epochs_array ] # 1 instead of 0\n",
    "\n",
    "lable_list= healthy_epochs_array_lable+ patient_epochs_array_lable\n",
    "\n",
    "lable_array= np.hstack(lable_list) #stacking each entry \n",
    "\n",
    "print(len(lable_list),len(lable_array),lable_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b1e7574-f4d0-42ef-aa73-daa0a938ea2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 9605\n"
     ]
    }
   ],
   "source": [
    "##groups \n",
    "group_list=[[i]*len(j) for i,j in enumerate(data_list)]\n",
    "group_array=np.hstack(group_list) #stacking \n",
    "print(len(group_list), len(group_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f967db95-600b-4cc1-aa1f-f62ba6b6d60f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##ML Libraries \n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "X=features_array\n",
    "y=lable_array\n",
    "groups=group_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace42541-edeb-493f-9fb7-c9e5fc77a81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HyperParameter tuning of Random foresnt with Group k fold applied \n",
    "\n",
    "model=RandomForestClassifier()\n",
    "pipe=Pipeline([('scaler',StandardScaler()),('clf',model)])\n",
    "param_grid = {'clf__n_estimators': [250,300,400], 'clf__max_features': [1,2,3,4]} ##best is estimators 60\n",
    "\n",
    "gscvRF =  GridSearchCV(pipe,param_grid, cv=4, return_train_score=False, n_jobs=-1)             \n",
    "gscvRF.fit(X,y,groups=groups)\n",
    "\n",
    "print(gscvRF.best_params_ , gscvRF.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53af9a3d-6256-4549-afaf-0e402e09a47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exporting the model\n",
    "import pickle\n",
    "with open('model_RF_PD','wb') as f:\n",
    "    pickle.dump(gscvRF,f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f427d10d-b061-476c-82a8-ac2bcb0fb541",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "TSub1_epochs_list = read_data('all_SP_edf/h01.edf')\n",
    "TSub1_epochs_array=np.array(TSub1_epochs_array)\n",
    "TSub1_features_array= concatenate_features(TSub1_epochs_array)\n",
    "\n",
    "model.predict(TSub1_features_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517a6500-c27f-4e54-ae0d-dc2d367eb174",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper parameter tuning for LR \n",
    "#Grid Search does permutation of all parameters (for automatic parameter tuning on scaled model ) #this also perfors iterative kfold cross validation on its own\n",
    "#multi_class='auto',\n",
    "\n",
    "model = LogisticRegression(multi_class='auto')\n",
    "pipe=Pipeline([('scaler',StandardScaler()),('classifier',model)])\n",
    "param_grid = [    \n",
    "    {'classifier__penalty' : ['l2'],\n",
    "    'classifier__C' : [300,350,400 ],\n",
    "    'classifier__solver' : ['lbfgs','newton-cg','liblinear'],\n",
    "    'classifier__max_iter' : [100,200]\n",
    "    }\n",
    "]\n",
    "\n",
    "gscvLr=GridSearchCV(pipe,param_grid,cv=4, n_jobs=-1) # 1st parameter model(in our case scaled model), second diffrent parameters we wana tweak of model                                                       #third number of splits in k fold             \n",
    "gscvLr.fit(X,y,groups=groups)\n",
    "\n",
    "print(gscvLr.best_params_ , gscvLr.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b14bab-4d82-4282-97e0-50a0c0af30be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('model_Lr_PD','wb') as f:\n",
    "    pickle.dump(gscvLr,f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27777f98-2ba7-4e61-bc01-5e6830d4a340",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install sklearn-rvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3f98466-f385-46a3-bbfd-197586661565",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\786me\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\786me\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn_rvm\\em_rvm.py:267: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  warnings.warn(\"The default value of gamma will change \"\n",
      "C:\\Users\\786me\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn_rvm\\em_rvm.py:324: UserWarning: Hessian not positive definite\n",
      "  warnings.warn(\"Hessian not positive definite\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m param_grid\u001b[38;5;241m=\u001b[39m{}\n\u001b[0;32m      4\u001b[0m gscvRVC\u001b[38;5;241m=\u001b[39mGridSearchCV(model,param_grid,cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mgscvRVC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:910\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    908\u001b[0m refit_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    909\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 910\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    911\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    912\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn_rvm\\em_rvm.py:344\u001b[0m, in \u001b[0;36mEMRVR.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    341\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing Pseudo-Inverse\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    342\u001b[0m     upper_inv \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mpinv(upper)\n\u001b[1;32m--> 344\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSigma_ \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupper_inv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupper_inv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconj\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmu_ \u001b[38;5;241m=\u001b[39m (upper_inv \u001b[38;5;241m@\u001b[39m (\n\u001b[0;32m    347\u001b[0m         upper_inv\u001b[38;5;241m.\u001b[39mconj()\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mPhi_\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m y)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_\n\u001b[0;32m    349\u001b[0m \u001b[38;5;66;03m# Equivalent sigma_diag = np.diag(self.Sigma_)\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn_rvm import EMRVR\n",
    "model=EMRVR()\n",
    "param_grid={}\n",
    "gscvRVC=GridSearchCV(model,param_grid,cv=4, n_jobs=-1)\n",
    "gscvRVC.fit(X,y,groups=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf6318f-70ed-403c-bffb-1865c5b4f7b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
